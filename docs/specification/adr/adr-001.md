# Nikaia Compiler Architecture (ADR-001)
**Document:** Implementation Specification
**Version:** 0.0.4 (Implementation Draft)
**Date:** January 17, 2026
**Status:** Active

---

## Chapter 1: Introduction and Context

This document defines the fundamental technical implementation of the Nikaia compiler (`nikaiac`). It documents the architectural decision to move away from a classic transpiler approach (Source-to-Source) in favor of a monolithic integration into the Rust Compiler Frontend (**"Rustc Driver Pattern"**).

### 1.1. The Driver Approach
Nikaia is not implemented as an external preprocessor that writes `.rs` files to disk. Instead, `nikaiac` acts as a wrapper around `rustc`, leveraging its internal APIs (`rustc_driver`, `rustc_interface`) directly.

**The Compilation Flow:**
1.  **Frontend (Nikaia):** Parsing `.nika` files into the Nikaia AST.
2.  **Semantic Analysis:** Validating Profile Constraints (Lite vs. Advanced) and resolving Extensions.
3.  **Lowering (In-Memory):** Transforming the Nikaia AST directly into a Rust `TokenStream`.
4.  **Injection:** Passing the `TokenStream` to the Rust compiler process as virtual input.
5.  **Backend (Rustc):** Macro expansion, Type Checking, Optimization (LLVM), and Code Generation.

### 1.2. Motivation
* **Macro Support:** Generated code must enter the compiler *before* macro expansion occurs.
* **Configuration Injection:** The driver dynamically sets flags based on the profile (e.g., `-C panic=abort` for Lite).
* **Error Mapping:** Using internal `Span` structures allows mapping errors directly back to the `.nika` source file, rather than the generated Rust code.

### 1.3. Version Pinning
Since Rust's internal APIs are unstable, Nikaia enforces strict coupling to a specific compiler version. Every Nikaia release includes a `rust-toolchain.toml` file pinning an exact Nightly build of Rust.

---

## Chapter 2: The Compiler Implementation (`nikaiac`)

The compiler is written in Nikaia itself ("Dogfooding").

### 2.1. Module Structure
* `nikaiac::ast`: The Data Model (Abstract Syntax Tree).
* `nikaiac::parser`: The Grammar definitions.
* `nikaiac::analysis`: Semantic analysis and method resolution.
* `nikaiac::lowering`: Transformation Engine (AST -> TokenStream).
* `nikaiac::driver`: Interface to `rustc_driver`.

### 2.2. The Data Model (`nikaiac::ast`)
The AST reflects the **Unified Types** and new **Arrow Syntax**.

```nika
// ast.nika
pub enum Expr {
    LiteralInt(i64),
    LiteralStr(String),
    Variable(String),
    
    // Binary Operation: 1 + 2
    Binary { 
        op: BinOp, 
        left: Shared[Expr], 
        right: Shared[Expr] 
    },
    
    // Block: { ... }
    Block(Vec[Stmt]),
    
    // Closures (Arrow Syntax)
    // Covers: arg => expr, (a,b) => { ... }, and { ... } (Block Lambdas)
    Closure {
        args: Vec[Ident],
        body: Shared[Expr],
        is_move: bool // 'move' keyword
    },
    
    // Async Control Flow
    Select(Vec[SelectBranch]),
    Spawn(Shared[Expr])
}
```

### 2.3. The Parser (`nikaiac::parser`)
The parser uses the native `grammar` DSL. It is updated to parse **Arrow Syntax** (`=>`).

```nika
// parser.nika
use crate::ast::{Expr, Stmt}

pub grammar CompilerGrammar {
    option recursion_limit = 256;

    pub rule compilation_unit -> Vec[Stmt] = stmt()*

    rule stmt -> Stmt = 
        | import_stmt()
        | let_stmt()
        | expr_stmt()

    // Example: let x = 5
    rule let_stmt -> Stmt = {
        "let" name:ident() "=" val:expr()
    } -> { Stmt::Let { name, value: val } }

    // Parsing Closures (Simplified)
    // Matches: "move" (opt) "{" ... "}"  OR  ident "=>" expr
    rule closure -> Expr = 
        | move_kwd:("move")? body:block() -> {
            Expr::Closure { args: [], body, is_move: move_kwd.is_some() }
        }
        | arg:ident() "=>" body:expr() -> {
            Expr::Closure { args: [arg], body, is_move: false }
        }
}
```

### 2.4. Semantic Analysis (`nikaiac::analysis`)
This phase enforces constraints specific to **Lite** or **Advanced** profiles.

```nika
// analysis.nika
pub fn check_constraints(module: &Module, profile: Profile) throws CompileError {
    // Constraint Check
    if profile == Profile::Lite {
        for stmt in module.stmts {
            if let Stmt::Import { path } = stmt {
                // Forbid manual threading in Lite
                if path.starts_with("std::thread") {
                    throw CompileError(
                        "Module 'std::thread' is forbidden in Lite Profile. " +
                        "Use 'spawn' for safe concurrency."
                    )
                }
            }
        }
    }
    register_extensions(module)
}
```

---

## Chapter 3: The Lowering Engine (`nikaiac::lowering`)

The core of the compiler is the `LoweringContext`, which translates Nikaia constructs into Rust tokens.

### 3.1. Transformation Logic
This section demonstrates how the **Advanced Profile** and **Block Lambdas** are handled.

**Example: Lowering a `spawn` call**

*Input (Nikaia AST):*
`spawn({ do_work() })` (Block Lambda)

*Lowering Logic (Pseudocode in Compiler):*
```rust
fn lower_spawn(closure_body: NikaiaExpr) -> TokenStream {
    // 1. Profile Check: Lite or Advanced?
    // We select the appropriate runtime backend.
    let spawner_func = match self.profile {
        Profile::Lite => "tokio::task::spawn_local",
        Profile::Advanced => "tokio::task::spawn" // formerly 'Standard'
    };

    // 2. Token Generation
    // We inject `async move` because Nikaia tasks are implicitly async state machines.
    // The user writes synchronous-looking code inside the block,
    // but we wrap it in an async block for the Rust compiler.
    quote! {
        #spawner_func(async move {
            #closure_body // Recursive lowering of the body
        })
    }
}
```

*Output (Rust TokenStream):*
`tokio::task::spawn(async move { do_work().await })`

### 3.2. Lowering Extension Methods
To map Ad-hoc Extensions (Chapter 4.2) to Rust, the compiler uses "Synthetic Traits".

```rust
// Generated Rust TokenStream
trait __NikaiaExtension_String_GenId123 {
    fn is_email(&self) -> bool;
}

impl __NikaiaExtension_String_GenId123 for String {
    fn is_email(&self) -> bool { ... }
}
```

### 3.3. Error Mapping (Span Preservation)
Nikaia constructs Rust tokens using Spans that point to the original `.nika` source file. This ensures that compiler errors highlight the Nikaia code, not the generated Rust boilerplate.

---

## Chapter 4: Verification and Bootstrapping

### 4.1. Codegen Tests
We use Snapshot Tests to verify that the lowering logic respects the profile.

```nika
// tests/codegen_test.nika
test "Spawn Lite Profile Generation" {
    // Input: Block Lambda Syntax
    let snippet = "spawn { 1 + 1 }"
    
    // Action
    let output = nikaiac::compile_snippet(snippet, Profile::Lite)
    
    // Assertion
    // Must use local spawner (Single Threaded)
    assert output.contains("tokio::task::spawn_local")
    // Must NOT use threaded spawner
    assert !output.contains("tokio::task::spawn(") 
}
```

### 4.2. Bootstrap Stages
As defined in Part III, Chapter 17, the build occurs in stages.
1.  **Stage 0:** Rust Prototype.
2.  **Stage 1:** Self-Hosting (Nikaia compiling Nikaia).
3.  **Stage 2:** Verification (Stage 1 compiling itself).

The result of Stage 2 must be capable of processing the Nikaia Standard Library and user code without errors.

